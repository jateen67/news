{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8oXoONPY7_d",
        "outputId": "6e4abcaf-afa7-40e4-bdc1-cd7f0bf07ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/news/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tO-iTbYogAH",
        "outputId": "58fea533-dd54-4908-c9c1-715b9e82c532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/news\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btXoai3reVj",
        "outputId": "595ef489-c1b8-44bf-ca31-1a146c9e4c54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb_reviews = pd.read_csv(\"imdb_reviews.csv\")\n",
        "# safety check\n",
        "imdb_reviews.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EZLI7YQr-ma"
      },
      "source": [
        "preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mBx1dLossAEM"
      },
      "outputs": [],
      "source": [
        "def preprocess(s):\n",
        "    s = s.lower()\n",
        "\n",
        "    s = re.compile(r'<[^>]+>').sub('', s)\n",
        "\n",
        "    # remove punctuations/numbers\n",
        "    s = re.sub('[^a-zA-Z]', ' ', s)\n",
        "\n",
        "    # remove single letters\n",
        "    s = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', s)\n",
        "\n",
        "    # remove places with more than one space\n",
        "    s = re.sub(r'\\s+', ' ', s)\n",
        "\n",
        "    # remove nltk stopwords (regex makes it go wayyy faster than the line below)\n",
        "    # s = ' '.join([word for word in s.split() if word not in (stopwords.words('english'))])\n",
        "    s = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*').sub('', s)\n",
        "\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHIxejCcwkG6",
        "outputId": "17313685-dbdf-4ba0-9785-bc11b440384a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "use rust blllllazingly fast code amazing\n"
          ]
        }
      ],
      "source": [
        "print(preprocess(\"i use ` rust for BLLLLLAZINGLY fast code    ... its amazing\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0o38gkn1iLP",
        "outputId": "19959e31-9bfb-4d39-82c4-1431b39fb61c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wonderful little production filming technique unassuming old time bbc fashion gives comforting sometimes discomforting sense realism entire piece actors extremely well chosen michael sheen got polari voices pat truly see seamless editing guided references williams diary entries well worth watching terrificly written performed piece masterful production one great master comedy life realism really comes home little things fantasy guard rather use traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell murals decorating every surface terribly well done \n"
          ]
        }
      ],
      "source": [
        "# preprocessing all reviews\n",
        "preprocessed_text = []\n",
        "\n",
        "for review in list(imdb_reviews['review']):\n",
        "    preprocessed_text.append(preprocess(review))\n",
        "\n",
        "print(preprocessed_text[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXo0bfqi22W8",
        "outputId": "4206fb9c-c0c5-4b05-9ab6-62cae0dca008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# converting each review's \"sentiment\" column value to 1 and 0 instead of \"positive\" and \"negative\"\n",
        "imdb_sentiments = imdb_reviews['sentiment']\n",
        "sentiments = []\n",
        "\n",
        "for sentiment in imdb_sentiments:\n",
        "    if sentiment == \"positive\":\n",
        "        sentiments.append(1)\n",
        "    else:\n",
        "        sentiments.append(0)\n",
        "\n",
        "sentiments = np.array(sentiments)\n",
        "\n",
        "print(sentiments[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OLjTfAOJ4T66"
      },
      "outputs": [],
      "source": [
        "# spliting data into training and test set data for the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessed_text, sentiments, test_size=0.25, random_state=42)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
