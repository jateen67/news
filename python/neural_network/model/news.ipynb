{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8oXoONPY7_d",
        "outputId": "6e4abcaf-afa7-40e4-bdc1-cd7f0bf07ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/news/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tO-iTbYogAH",
        "outputId": "58fea533-dd54-4908-c9c1-715b9e82c532"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/news\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_reviews = pd.read_csv(\"imdb_reviews.csv\")\n",
        "# safety check\n",
        "imdb_reviews.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3btXoai3reVj",
        "outputId": "595ef489-c1b8-44bf-ca31-1a146c9e4c54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing"
      ],
      "metadata": {
        "id": "0EZLI7YQr-ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_tags(s):\n",
        "    return re.compile(r'<[^>]+>').sub('', s)\n",
        "\n",
        "def preprocess(s):\n",
        "    s = s.lower()\n",
        "\n",
        "    s = remove_html_tags(s)\n",
        "\n",
        "    # remove punctuations/numbers\n",
        "    s = re.sub('[^a-zA-Z]', ' ', s)\n",
        "\n",
        "    # remove single letters\n",
        "    s = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', s)\n",
        "\n",
        "    # remove places with more than one space\n",
        "    s = re.sub(r'\\s+', ' ', s)\n",
        "\n",
        "    # remove nltk stopwords (regex makes it go wayyy faster than the line below)\n",
        "    # s = ' '.join([word for word in s.split() if word not in (stopwords.words('english'))])\n",
        "    s = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*').sub('', s)\n",
        "\n",
        "    return s"
      ],
      "metadata": {
        "id": "mBx1dLossAEM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocess(\"i use ` rust for BLLLLLAZINGLY fast code    ... its amazing\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHIxejCcwkG6",
        "outputId": "17313685-dbdf-4ba0-9785-bc11b440384a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use rust blllllazingly fast code amazing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing all reviews\n",
        "preprocessed_text = []\n",
        "\n",
        "for review in list(imdb_reviews['review']):\n",
        "    preprocessed_text.append(preprocess(review))\n",
        "\n",
        "print(preprocessed_text[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0o38gkn1iLP",
        "outputId": "19959e31-9bfb-4d39-82c4-1431b39fb61c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wonderful little production filming technique unassuming old time bbc fashion gives comforting sometimes discomforting sense realism entire piece actors extremely well chosen michael sheen got polari voices pat truly see seamless editing guided references williams diary entries well worth watching terrificly written performed piece masterful production one great master comedy life realism really comes home little things fantasy guard rather use traditional dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell murals decorating every surface terribly well done \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting each review's \"sentiment\" column value to 1 and 0 instead of \"positive\" and \"negative\"\n",
        "imdb_sentiments = imdb_reviews['sentiment']\n",
        "sentiments = []\n",
        "\n",
        "for sentiment in imdb_sentiments:\n",
        "    if sentiment == \"positive\":\n",
        "        sentiments.append(1)\n",
        "    else:\n",
        "        sentiments.append(0)\n",
        "\n",
        "sentiments = np.array(sentiments)\n",
        "\n",
        "print(sentiments[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXo0bfqi22W8",
        "outputId": "4206fb9c-c0c5-4b05-9ab6-62cae0dca008"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting data into training and test set data for the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessed_text, sentiments, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "OLjTfAOJ4T66"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}